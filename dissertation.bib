% Encoding: UTF-8
@book{mittelbach2004latex,
  title={The LaTeX companion},
  author={Mittelbach, F. and Goossens, M. and Braams, J. and Rowley, C.},
  isbn={9780201362992},
  lccn={2003070810},
  series={Addison-Wesley series on tools and techniques for computer typesetting},
  url={http://books.google.com/books?id=ngwZAQAAIAAJ},
  year={2004},
  publisher={Addison-Wesley}
}

@Manual{xparse,
  title    = {The xparse package: Document command parser},
  author   = {The LaTeX3 Project},
  month    = dec,
  year     = {2017},
  language = {English},
  url      = {http://mirrors.ctan.org/macros/latex/contrib/l3packages/xparse.pdf},
}

@PhdThesis{Bambach2016,
  author   = {Bambach,Sven},
  title    = {Analyzing hands with first-person computer vision},
  school   = {Indiana University, Bloomington},
  year     = {2016},
  note     = {Copyright - Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works; Last updated - 2016-12-05},
  abstract = {Egocentric cameras aim to approximate a person's field of view, which provides insight into how people interact with the world. Consequently, many cognitive researchers are interested in using wearable camera systems as tools to study attention, perception, and learning. These systems typically capture vast amounts of image data, so to fully harness the potential of this novel observational paradigm, sophisticated techniques to automatically annotate and understand the data are needed. However, analyzing first-person imagery introduces many unique challenges, as it is usually recorded passively without artistic intent and therefore lacks many of the clean characteristics of traditional photography. This thesis presents novel computer vision approaches to automatically analyze first-person imaging data. The focus of these approaches lies in extracting and understanding hands in the egocentric field of view. Hands are almost omnipresent and constitute our primary channel of interaction with the physical world. To that end, we argue that analyzing hands is an important factor towards the goal of automatically understanding human behavior from egocentric images and videos. We propose three different approaches that aim to extract meaningful and useful information about hands in the context of social interactions. First, we consider laboratory videos of joint toy play between infants and parents, and develop a method to track and, importantly, distinguish hands based on spatial constraints imposed by the egocentric paradigm. This method allows us to collect fine-grained hand appearance statistics that contribute new evidence towards how infants and their parents coordinate attention through eye-hand coordination. Next, we build upon this approach to develop a general, probabilistic framework that jointly models temporal and spatial biases of hand locations. We demonstrate that this approach achieves notable results in disambiguating hands even when combined with noisy initial detections that may occur in naturalistic videos. Finally, we ask to what extent we can identify hand types and poses directly based on visual appearances. We collect a large-scale egocentric video dataset with pixel-level hand annotations to permit the training of data-driven recognition models like convolutional neural networks. Results indicate that not only can we distinguish hands, but also infer activities from hand poses.},
  isbn     = {9781369169201},
  journal  = {ProQuest Dissertations and Theses},
  keywords = {Applied sciences; Psychology; Computer vision; Convolutional neural networks; Egocentric vision; Graphical models; Hand analysis; Wearable cameras; Cognitive psychology; Computer science; 0633:Cognitive psychology; 0984:Computer science},
  language = {English},
  pages    = {128},
  url      = {http://proxyiub.uits.iu.edu/login?url=https://search.proquest.com/docview/1842431292?accountid=11620},
}

@PhdThesis{Agmon2016,
  author   = {Agmon,Eran},
  title    = {The foundation of agency: An exploration of how minimal organisms emerge from and adapt to their environments},
  school   = {Indiana University, Bloomington},
  year     = {2016},
  note     = {Copyright - Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works; Last updated - 2016-11-08},
  abstract = {Agents are of central importance to cognitive science, but research usually takes them as pre-given and proceeds to study some of their particular aspects, often without awareness of or a definite answer to the question, ``what is an agent?'' The conceptual framework of autopoiesis and enaction provides a foundation that defines agents as emergent individuals that act in an environment to fulfill their physiological needs. To establish this definition in concrete examples, this dissertation introduces computational models and analyses that demonstrate several properties of agents. It examines an artificial chemistry that supports the emergence of minimal protocells. These protocells have a metabolism made of autocatalytic components, and an external boundary that self-assembles and encapsulates the metabolism, keeping it from diffusing into the environment. Metabolism and boundary are mutually enabling processes, which together counter the effects of diffusion and decay. When their symbiosis is broken, the protocell disintegrates. 
Systematic analysis reveals the rich consequences of protocellular organizations. Ontogenies are mapped as network structures, with the networks' nodes as reachable protocell morphologies and its edges as the transitions between morphologies. Analyses of these networks reveal properties such as irreversibility (some changes cannot be reversed under any circumstance) and branching (unfolding down one ontogeny excludes morphologies accessible by other ontogeny). Viability is quantified as expected lifespan, and measured across different protocell configurations. This provides a basis for measuring agents' basic goal of adaptivity -- to increase their viability in a given environment through internal restructuring or environmental change. 
The cellular Potts model (CPM) framework is examined to study structural coupling (the bi-directional interactions between an agent and environment). The network-based methodology for analyzing ontogenies is extended to incorporate a local environmental state and is demonstrated in a CPM. This reveals several interesting features, such as a divergence in the space of possible ontogenies when placed in different environments, and that niche construction can increase an individual's viability.},
  isbn     = {9781369047004},
  journal  = {ProQuest Dissertations and Theses},
  keywords = {Biological sciences; Applied sciences; Health and environmental sciences; Autopoiesis; Ontogeny; Protocells; Structural coupling; Viability; Biology; Developmental biology; Computer science; 0306:Biology; 0758:Developmental biology; 0984:Computer science},
  language = {English},
  pages    = {138},
  url      = {http://proxyiub.uits.iu.edu/login?url=https://search.proquest.com/docview/1832064738?accountid=11620},
}

@PhdThesis{Hansen2015,
  author   = {Hansen,Michael},
  title    = {Quantifying code complexity and comprehension},
  school   = {Indiana Univeristy, Bloomington},
  year     = {2015},
  note     = {Copyright - Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works; Last updated - 2016-06-06},
  abstract = {What factors impact how difficult code is to understand? Small, simple programs are often easier to grasp, but can still be locally ambiguous, visually confusing, or violate implicit expectation. The cognitive complexity of a program is something more than its line length, visual layout, and problem domain. It is a gestalt phenomena that arises when a programmer must perform a specific task on a given program or segment of code. Modeling these phenomena is a challenging real-world problem at the intersection of computer science and cognitive science. Programmers have been the subject of traditional psychology experiments for several decades, correlating code features with task performance. The recent inclusion of eye-tracking in program comprehension experiments, however, has given researchers a unique window into programmers' cognitive processes. Advances in the state of the art for quantitative cognitive modeling have opened the door for a unique confluence of technique and technology: quantitative, cognitive models of human program comprehension. We present an experiment in which 162 programmers, from beginner to expert, were asked to predict the printed output of ten short Python programs. Different versions of the same program were randomly selected, exposing groups of participants to minor variations in code spacing, naming, and function. A subset of participants performed the experiment in front of an eye tracker, allowing for a combined analysis of reading and response behavior. The observed errors, timings, and keystrokes formed the basis for two program comprehension models: one modeling correct participants' low-level reading and response behavior, and the other modeling incorrect participants' interpretation errors. These models form the foundation for future research in program comprehension, and join the frontiers of quantitative modeling in cognitive science.},
  isbn     = {9781339227115},
  journal  = {ProQuest Dissertations and Theses},
  keywords = {Applied sciences; Psychology; Code complexity; Cognitive model; Domain knowledge; Eye tracking; Program comprehension; Cognitive psychology; Computer science; 0633:Cognitive psychology; 0984:Computer science},
  language = {English},
  pages    = {314},
  url      = {http://proxyiub.uits.iu.edu/login?url=https://search.proquest.com/docview/1736093605?accountid=11620},
}

@Comment{jabref-meta: databaseType:bibtex;}
